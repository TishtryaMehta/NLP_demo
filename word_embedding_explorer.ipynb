{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Google News Word2Vec model\n",
    "path_model=\"Q:\\\\Oflog\\\\NLP\\\\Inputs\\\\Pretrained_WE_models\\\\\"\n",
    "wv = KeyedVectors.load(path_model+\"vectors_word2vec-google-news-300.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate a single word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_word='apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your chosen word is apple\n",
      "Length of vector 300\n",
      "First five elements of vector [-0.06445312 -0.16015625 -0.01208496  0.13476562 -0.22949219]\n",
      "Similarity of chosen word to the word \"Mango\": 0.57518554\n",
      "Similarity of chosen word to the word \"Parliment\": 0.14690015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Your chosen word is:', chosen_word)\n",
    "print('Length of vector', len(wv[chosen_word]))\n",
    "print('First five elements of vector', wv[chosen_word][0:5])\n",
    "print('Similarity of chosen word to the word \"Mango\":', wv.similarity(chosen_word, \"mango\"))\n",
    "print('Similarity of chosen word to the word \"Parliment\":', wv.similarity(chosen_word, \"parliment\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare similarity of several words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n",
      "'car'\t'petrol'\t0.39\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "    ('car', 'petrol')\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain similar words through mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar works though vector addition subtraction;\n",
    "E.g. start at positive vectors, sum up, and subtract any negative to get final vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532192707061768), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763688564300537), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565720081329346)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the equivalent of 'King' - 'Man'. Note that this database is trained on the news, so may result in positical answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.4295138418674469),\n",
       " ('queen', 0.39028695225715637),\n",
       " ('Pansy_Ho_Chiu', 0.3827225863933563),\n",
       " ('monarch', 0.3633837103843689),\n",
       " ('kingdom', 0.361450731754303),\n",
       " ('royal_palace', 0.3535977900028229),\n",
       " ('Savory_aromas_wafted', 0.35272470116615295)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['king'], negative=['man'], topn=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
